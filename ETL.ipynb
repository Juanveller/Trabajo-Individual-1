{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL:\n",
    "#### 1 - Extraccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga de datos del archivo \"movies_dataset\": Utilizando la biblioteca pandas, se cargó el archivo movies_dataset.csv y se realizó una inspección inicial para evaluar la estructura de datos, columnas y tipos de datos presentes. Se visualizaron las primeras filas para una revisión preliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos el archivo\n",
    "movies_dataset_df = pd.read_csv(\"movies_dataset.csv\")\n",
    "\n",
    "# Realizamos una inspección inicial\n",
    "print(movies_dataset_df.info())  # Información general de las columnas y tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df.head()  # Primeras filas del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carga de datos del archivo \"credits\": De igual manera, se cargó el archivo credits.csv y se realizó la misma inspección inicial de estructura y tipos de datos, con el objetivo de comprender los datos para su posterior transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el archivo\n",
    "credits_df = pd.read_csv(\"credits.csv\")\n",
    "\n",
    "# Realizamos una inspección inicial\n",
    "print(credits_df.info())  # Información general de las columnas y tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df.head()  # Primeras filas del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación del dataset \"movies_dataset\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminación de columnas irrelevantes: Se suprimieron columnas no requeridas (video, imdb_id, adult, original_title, poster_path, homepage) para optimizar el dataset según las necesidades del cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas innecesarias\n",
    "movies_dataset_df = movies_dataset_df.drop(columns=['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage'])\n",
    "\n",
    "# Confirmamos la eliminación de las columnas\n",
    "print(movies_dataset_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisión y tratamiento de valores faltantes: Se identificaron y contaron los valores nulos por columna, y en el caso de las columnas revenue y budget, se rellenaron con ceros. Estos campos fueron convertidos a tipo numérico para asegurar un correcto procesamiento y análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos los valores faltantes\n",
    "missing_values = movies_dataset_df.isnull().sum().sort_values(ascending=False) #recuento de valores nulos en orden descendente\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de columna de retorno (return): Para esta columna, se calculó la relación entre revenue y budget, asignando cero cuando budget tenía un valor nulo o era igual a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos valores nulos en las columnas 'revenue' y 'budget' con 0\n",
    "movies_dataset_df['revenue'] = movies_dataset_df['revenue'].fillna(0)\n",
    "movies_dataset_df['budget'] = movies_dataset_df['budget'].fillna(0)\n",
    "\n",
    "# Confirmamos de que ya no hay valores nulos en 'revenue' y 'budget'\n",
    "print(\"Valores nulos en 'revenue':\", movies_dataset_df['revenue'].isnull().sum())\n",
    "print(\"Valores nulos en 'budget':\", movies_dataset_df['budget'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'budget' y 'revenue' a numérico, reemplazando valores no convertibles por 0\n",
    "movies_dataset_df['budget'] = pd.to_numeric(movies_dataset_df['budget'], errors='coerce')\n",
    "movies_dataset_df['revenue'] = pd.to_numeric(movies_dataset_df['revenue'], errors='coerce')\n",
    "\n",
    "# Creamos la columna 'return' dividiendo 'revenue' entre 'budget'\n",
    "movies_dataset_df['return'] = movies_dataset_df.apply(lambda row: row['revenue'] / row['budget'] if row['budget'] > 0 else 0, axis=1)\n",
    "\n",
    "# Confirmamos la creación de la nueva columna\n",
    "print(movies_dataset_df[['revenue', 'budget', 'return']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación de la columna release_date: Se eliminaron las filas con valores nulos en release_date, se convirtió al formato de fecha estándar (AAAA-MM-DD) y se generó la columna release_year extrayendo el año de la fecha de lanzamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"release_date\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos filas con valores nulos en la columna 'release_date'\n",
    "movies_dataset_df = movies_dataset_df.dropna(subset=['release_date'])\n",
    "# Confirmamos la eliminación\n",
    "print(\"Valores nulos en 'release_date' después de la eliminación:\", movies_dataset_df['release_date'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'release_date' al formato AAAA-mm-dd\n",
    "movies_dataset_df['release_date'] = pd.to_datetime(movies_dataset_df['release_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Creamos la columna 'release_year' extrayendo solo el año\n",
    "movies_dataset_df['release_year'] = pd.to_datetime(movies_dataset_df['release_date'], errors='coerce').dt.year\n",
    "\n",
    "# Confirmamos los cambios\n",
    "print(movies_dataset_df[['release_date', 'release_year']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desanidado de columnas anidadas: Con ayuda de la librería ast, se desanidaron los valores en las columnas belongs_to_collection, production_companies, genres, production_countries y spoken_languages, extrayendo solo la información relevante como nombres de colecciones, compañías de producción, géneros, países de producción y lenguajes hablados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"belongs_to_collection\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la libreria ast (arboles de sintaxis abrstracta)\n",
    "import ast \n",
    "\n",
    "# Convertimos a diccionario y extraemos el nombre 'name' de la colección si existe\n",
    "movies_dataset_df['belongs_to_collection'] = movies_dataset_df['belongs_to_collection'].apply(\n",
    "    lambda x: ast.literal_eval(x).get('name') if pd.notnull(x) and isinstance(x, str) and x.startswith('{') else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"belongs_to_collection\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"production_companies\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos los nombres de las compañías de producción\n",
    "movies_dataset_df['production_companies'] = movies_dataset_df['production_companies'].apply(\n",
    "    lambda x: [i['name'] for i in ast.literal_eval(x)] if pd.notnull(x) and isinstance(x, str) and x.startswith('[') else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"production_companies\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"genres\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extramos los nombres de la columna géneros\n",
    "movies_dataset_df['genres'] = movies_dataset_df['genres'].apply(\n",
    "    lambda x: [i['name'] for i in ast.literal_eval(x)] if pd.notnull(x) and isinstance(x, str) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"genres\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"production_countries\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos los nombres de las compañías de producción\n",
    "movies_dataset_df['production_countries'] = movies_dataset_df['production_countries'].apply(\n",
    "    lambda x: [i['name'] for i in ast.literal_eval(x)] if pd.notnull(x) and isinstance(x, str) and x.startswith('[') else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"production_countries\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"spoken_languages\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df['spoken_languages'] = movies_dataset_df['spoken_languages'].apply(\n",
    "    lambda x: [i['name'] for i in ast.literal_eval(x)] if pd.notnull(x) and isinstance(x, str) and x.startswith('[') else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df[\"spoken_languages\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos nuevamente el Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado de idiomas: Para reducir el tamaño del archivo y centrarse en los idiomas principales, se seleccionaron las filas que contenían solo los cinco idiomas más frecuentes: English, Spanish, Français, Italiano y Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_idiomas = movies_dataset_df[\"spoken_languages\"].value_counts()\n",
    "top_5_idiomas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define los idiomas deseados\n",
    "idiomas_deseados = ['English', 'Spanish', 'Français',\"Italiano\", 'Portuguese']\n",
    "\n",
    "# Filtra el dataframe para mantener solo las filas que contienen los idiomas deseados en 'spoken_languages'\n",
    "movies_dataset_df = movies_dataset_df[\n",
    "    movies_dataset_df['spoken_languages'].apply(lambda idiomas: any(idioma in idiomas_deseados for idioma in idiomas) if idiomas else False)\n",
    "]\n",
    "\n",
    "# Revisa el resultado\n",
    "movies_dataset_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente revisamos el dataframe y vemos que sigue habendo columnas que no serian necesarias para cumplir con los requerimientos por lo que procedemos a eliminarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos las columnas esistentes en el dataframe\n",
    "print(movies_dataset_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminación adicional de columnas innecesarias: Tras una última revisión, se eliminaron las columnas overview, tagline, status, spoken_languages, original_language y popularity para ajustar el dataset a los requerimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_df = movies_dataset_df.drop(columns=['overview', 'tagline', 'status', 'spoken_languages', 'original_language', 'popularity'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Transformación del dataset \"credits\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df[\"cast\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción de información específica de cast y crew: Mediante una función personalizada, se extrajeron de la columna cast únicamente los datos de character y name y, de la columna crew, se extrajeron solo los nombres de los directores, manteniendo así los detalles clave requeridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la libreria ast (arboles de sintaxis abstracta)\n",
    "import ast \n",
    "# Creamos una funcion para extraer solo 'character' y 'name' de la columna 'cast'\n",
    "def extraer_cast_info(cast_data):\n",
    "    try:\n",
    "        cast_list = ast.literal_eval(cast_data) # Intenta convertir de cadena a lista de diccionarios\n",
    "        return [{'character': person['character'], 'name': person['name']} for person in cast_list] #De poder hacerlo el paso anterior, extrae solo 'character' y 'name'\n",
    "    except (ValueError, TypeError):\n",
    "        return None # De no poder convertir a diccionario por error de valor o tipo devuelve None\n",
    "\n",
    "# Aplicamos la función al DF para crear una nueva columna 'cast_info'\n",
    "credits_df['cast_info'] = credits_df['cast'].apply(extraer_cast_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df[\"cast_info\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una unción para extraer sólo el nombre de los directores de la columna 'crew'\n",
    "def extraer_director_info(crew_data):\n",
    "    try:\n",
    "        crew_list = ast.literal_eval(crew_data)# Intenta convertir de cadena a lista de diccionarios\n",
    "        return [person['name'] for person in crew_list if person['job'] == 'Director'] #De poder hacerlo, filtra solo los directores y extrae sus nombres\n",
    "    except (ValueError, TypeError): # De no poder convertir a diccionario por error de valor o tipo devuelve None\n",
    "        return None\n",
    "\n",
    "# Aplicamos la función al DF para crear una nueva columna 'director_info'\n",
    "credits_df['director_info'] = credits_df['crew'].apply(extraer_director_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df['director_info'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de columnas originales: Una vez creada la información necesaria en nuevas columnas (cast_info y director_info), se eliminaron las columnas cast y crew para simplificar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df.drop(columns=[\"cast\",\"crew\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenación y guardado final: Los DataFrames transformados (movies_dataset_df y credits_df) fueron concatenados en un solo DataFrame, el cual fue guardado en un nuevo archivo llamado DF_final.csv, que contiene los datos finales listos para análisis y consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_limpio = pd.concat([movies_dataset_df,credits_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_limpio.to_csv(\"DF_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sistema de Recomendación Basado en Similitud de Coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desarrollar un sistema de recomendación de películas, utilizaremos la similitud de coseno, que nos permite medir la similitud entre vectores de características. A continuación, detallamos cada paso del proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Importación de Librerías y Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, importamos las librerías necesarias y cargamos el archivo preprocesado, DF_final.csv, que contiene las columnas y valores listos para construir el sistema de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset final\n",
    "df_modelo = pd.read_csv(\"DF_final.csv\")\n",
    "print(\"Dimensiones del dataset:\", df_modelo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Selección y Limpieza de Parámetros Clave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso, seleccionamos las columnas de interés para el sistema de recomendación. Las características numéricas incluyen release_year, vote_average, vote_count, y runtime. Las características categóricas abarcan genres, production_companies, y production_countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas en listas si aún no lo están\n",
    "df_modelo['genres'] = df_modelo['genres'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "df_modelo['production_companies'] = df_modelo['production_companies'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "df_modelo['production_countries'] = df_modelo['production_countries'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el modelo, filtramos las 50 compañías de producción y países más comunes, manteniendo solo estos en cada película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las 50 compañías y países más comunes\n",
    "top_companies = df_modelo['production_companies'].explode().value_counts().head(50).index\n",
    "top_countries = df_modelo['production_countries'].explode().value_counts().head(50).index\n",
    "\n",
    "df_modelo['production_companies'] = df_modelo['production_companies'].apply(lambda x: [i for i in x if i in top_companies])\n",
    "df_modelo['production_countries'] = df_modelo['production_countries'].apply(lambda x: [i for i in x if i in top_countries])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Codificación de Características Categóricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos MultiLabelBinarizer para transformar las columnas de géneros, compañías de producción y países en variables binarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de géneros, compañías de producción y países de producción\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "genres_encoded = mlb_genres.fit_transform(df_modelo['genres'])\n",
    "\n",
    "mlb_companies = MultiLabelBinarizer()\n",
    "companies_encoded = mlb_companies.fit_transform(df_modelo['production_companies'])\n",
    "\n",
    "mlb_countries = MultiLabelBinarizer()\n",
    "countries_encoded = mlb_countries.fit_transform(df_modelo['production_countries'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Normalización de Características Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las características numéricas, usamos MinMaxScaler para que todos los valores se encuentren en un rango entre 0 y 1, facilitando la comparación en la matriz de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de características numéricas\n",
    "scaler = MinMaxScaler()\n",
    "numerical_features = df_modelo[['release_year', 'vote_average', 'vote_count', 'runtime']].fillna(0)\n",
    "numerical_scaled = scaler.fit_transform(numerical_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 5: Combinación de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fusionamos las características numéricas normalizadas y las variables binarias en un solo conjunto de características, listo para el cálculo de similitud de coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinación de todas las características en un solo array de características\n",
    "caracteristicas = np.hstack([numerical_scaled, genres_encoded, companies_encoded, countries_encoded])\n",
    "print(\"Shape de las características combinadas:\", caracteristicas.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 6: Creación de DataFrame de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un nuevo DataFrame, df_caracteristicas, que contiene todas las características necesarias para el sistema de recomendación y añadimos el índice original para referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de características y añadir el índice original\n",
    "df_caracteristicas = pd.DataFrame(caracteristicas)\n",
    "df_caracteristicas['original_index'] = df_modelo.index\n",
    "df_caracteristicas['title'] = df_modelo['title'].values  # Añadir columna título\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos este DataFrame para futuras referencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caracteristicas.to_csv(\"df_caracteristicas.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 7: Cálculo de Similitud de Coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, calculamos la similitud de coseno entre las películas para recomendar aquellas que son más similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de la similitud de coseno\n",
    "matriz_caracteristicas = df_caracteristicas.drop(columns=['original_index', 'title']).values\n",
    "similitud_de_coseno = cosine_similarity(matriz_caracteristicas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
